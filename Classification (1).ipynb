{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a3d6f7f9-9c23-4fe7-99c7-1fc010b56feb",
   "metadata": {},
   "source": [
    "\n",
    "CLASSIFICATION:\n",
    "===============\n",
    "=>Classification is a supervised learning technique in machine learning ,\n",
    "where the goal is to categorize data points into predefined classes.\n",
    "It's used in various applications such as spam detection, image recognition, and medical diagnosis.\n",
    "\n",
    "=>Example: In a spam email detection system, the model classifies each email as either \"spam\" or \"not spam.\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "f18ad8ba-e26d-4dd4-aa77-f41d09584cc6",
   "metadata": {},
   "source": [
    "1]Logistic Regression\n",
    "--------------------\n",
    "Logistic regression is a linear model used for binary classification tasks. \n",
    "Instead of predicting a continuous value, it predicts the probability of a data point belonging to a particular class.\n",
    "Logistic regression uses the sigmoid function to map predicted values to probabilities between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "714cdc3b-12f8-443e-9955-f1247d77f4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Example: Predicting whether a customer will buy a product or not (Yes/No) based on features such as age and income.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "X = np.array([[20], [25], [30], [35], [40], [45], [50]])\n",
    "y = np.array([0, 0, 1, 0, 1, 1, 1])  # 0 = No, 1 = Yes\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a5e762a-c019-4b4b-95c8-69e9841ef01e",
   "metadata": {},
   "source": [
    "2]K-Nearest Neighbors (KNN)\n",
    "KNN is a non-parametric algorithm that classifies data based on the similarity to its \"K\" nearest neighbors.\n",
    "For a new data point, KNN identifies the K closest points in the training set and\n",
    "assigns the most common class among these neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb85738c-3b33-4a9a-af52-a09c385bdad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class for [4, 5]: [0]\n"
     ]
    }
   ],
   "source": [
    "#Example: Classifying if a flower is \"Iris-setosa\" or \"Iris-versicolor\" based on petal length and width.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Sample data\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [6, 7], [7, 8], [8, 9]])\n",
    "y = np.array([0, 0, 0, 1, 1, 1])\n",
    "\n",
    "# Model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "print(\"Predicted class for [4, 5]:\", knn.predict([[4, 5]]))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5a416dc-40cf-47ee-8355-3e72e643ec56",
   "metadata": {},
   "source": [
    "3] Support Vector Machines (SVM)\n",
    "SVM is a powerful classification algorithm that seeks to find a hyperplane that maximizes the margin between two classes.\n",
    "It’s effective in high-dimensional spaces and is commonly used for text classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e00d9e-a25e-47fe-bdfc-25bb5ea59a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class for [4, 5]: [0]\n"
     ]
    }
   ],
   "source": [
    "#Example: Classifying reviews as \"positive\" or \"negative.\"\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Sample data\n",
    "X = np.array([[2, 3], [3, 4], [1, 1], [6, 7], [7, 8], [8, 9]])\n",
    "y = np.array([0, 0, 0, 1, 1, 1])\n",
    "\n",
    "# Model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "print(\"Predicted class for [4, 5]:\", svm_model.predict([[4, 5]]))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6295f6a3-81df-405b-8c5e-c57fa4c11e08",
   "metadata": {},
   "source": [
    "4]. Decision Trees\n",
    "A decision tree is a flowchart-like structure where each internal node represents\n",
    "a decision based on a feature, each branch represents an outcome, and each leaf node represents a class label.\n",
    "It's intuitive and easy to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f15c092-0f99-41d3-8664-4530edbd21e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class for [75000, 750]: [1]\n"
     ]
    }
   ],
   "source": [
    "#Example: Predicting if a person will buy a house based on salary and credit score.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Sample data\n",
    "X = np.array([[60000, 650], [65000, 600], [70000, 700], [80000, 800]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "\n",
    "# Model\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "print(\"Predicted class for [75000, 750]:\", tree.predict([[75000, 750]]))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31d4fa2b-2170-4bcb-a26d-e8399ad1605a",
   "metadata": {},
   "source": [
    "Evaluation Metrics:\n",
    "========================\n",
    "Evaluation metrics are essential to understand the performance of classification models.\n",
    "The most commonly used metrics are:\n",
    "\n",
    "1]Accuracy\n",
    "The ratio of correct predictions to the total predictions.\n",
    "\n",
    "Accuracy=TP+TN/TP+TN+FP+FN\n",
    "​where:\n",
    "TP = True Positives\n",
    "TN = True Negatives\n",
    "FP = False Positives\n",
    "FN = False Negatives\n",
    "\n",
    "2]Precision\n",
    "The ratio of true positives to the sum of true positives and false positives. \n",
    "It shows how many of the predicted positive cases are actually positive.\n",
    "\n",
    "Precision=TP/TP+FP\n",
    "\n",
    "3]Recall\n",
    "The ratio of true positives to the sum of true positives and false negatives. \n",
    "It shows how many actual positive cases were correctly predicted.\n",
    "\n",
    "Recall=TP/TP+FN\n",
    "\n",
    "4]F1 Score\n",
    "The harmonic mean of precision and recall, providing a balanced measure.\n",
    "\n",
    "F1 Score=2×[Precision×Recall/Precision+Recall]\n",
    "\n",
    "​5]ROC-AUC (Receiver Operating Characteristic - Area Under Curve)\n",
    "The ROC-AUC score represents the model’s ability to distinguish between classes. A higher AUC indicates better performance.\n",
    "​\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f04dee0-7f73-4939-b3be-b932e63bc43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "ROC-AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Sample data\n",
    "X = np.array([[20], [25], [30], [35], [40], [45], [50]])\n",
    "y = np.array([0, 0, 1, 0, 1, 1, 1])  # 0 = No, 1 = Yes\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b12c392-8bdb-438f-9f99-ae489c4164e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
